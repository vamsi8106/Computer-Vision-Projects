# -*- coding: utf-8 -*-
"""M22RM002_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ztX85mXpsVlyL2aEsmVX6B7BlfJSrLnX
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2
import numpy as np
from sklearn.cluster import MiniBatchKMeans
from sklearn.neighbors import NearestNeighbors
from tqdm import tqdm
import tensorflow as tf
import matplotlib.pyplot as plt

# Load the CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

# Preprocess the images
def preprocess_images(images):
    images_gray = np.mean(images, axis=-1)
    images_resized = np.array([cv2.resize(img, (32, 32)) for img in images_gray])
    images_norm = (images_resized - np.mean(images_resized)) / np.std(images_resized)
    images_norm_uint8 = cv2.convertScaleAbs(images_norm, alpha=(255.0/2))
    return images_norm_uint8

x_train_preprocessed = preprocess_images(x_train)
x_test_preprocessed = preprocess_images(x_test)

# Extract local features using SIFT detector
def extract_local_features(images):
    sift = cv2.SIFT_create()
    features = []
    for img in tqdm(images):
        _, descriptors = sift.detectAndCompute(img, None)
        if descriptors is not None:
            features.append(descriptors)
    return np.vstack(features)


x_train_features = extract_local_features(x_train_preprocessed)
x_test_features = extract_local_features(x_test_preprocessed)

# Cluster the local features using k-means
n_clusters = 100
kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=1000, verbose=0).fit(x_train_features)


# Define the nearest neighbors object for computing distances between histograms
n_neighbors = 1000
if n_neighbors > x_train_features.shape[0]:
    n_neighbors = x_train_features.shape[0]
knn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')

# Compute the visual word histograms for the images
def compute_visual_word_histograms(images, kmeans, neighbors):
    histograms = []
    sift = cv2.SIFT_create()
    for img in tqdm(images):
        _, descriptors = sift.detectAndCompute(img, None)
        if descriptors is None:
            histograms.append(np.zeros(n_clusters))
        else:
            cluster_indices = kmeans.predict(descriptors)
            histogram, _ = np.histogram(cluster_indices, bins=n_clusters, range=(0, n_clusters-1))
            histogram_norm = histogram / np.linalg.norm(histogram)
            histograms.append(histogram_norm)
    histograms = np.array(histograms)
    if neighbors is not None:
        neighbors.fit(histograms)
    return histograms

# Compute the visual word histograms for the training and test sets
x_train_histograms = compute_visual_word_histograms(x_train_preprocessed, kmeans, knn)
x_test_histograms = compute_visual_word_histograms(x_test_preprocessed, kmeans, knn)

"""## TEST WITH INBUILT DATA SET"""

# Compute the top-5 similar images using visual BoW
def retrieve_similar_images(query_histogram, database_histograms, database_images,database_labels):
    _, indices = knn.kneighbors(query_histogram.reshape(1, -1))
    similar_images = database_images[indices[0]]
    similar_histograms = database_histograms[indices[0]]
    distances = np.linalg.norm(similar_histograms - query_histogram, axis=1)
    sorted_indices = np.argsort(distances)
    return similar_images[sorted_indices], distances[sorted_indices],database_labels[indices[0]][sorted_indices]

query_image_index = 9
query_histogram = x_test_histograms[query_image_index]
query_image = x_test[query_image_index]
similar_images, distances,labels = retrieve_similar_images(query_histogram, x_train_histograms, x_train,y_train)
print('Query image:')
plt.imshow(query_image)
plt.show()

print("Top 5 similar images")
for i in range(5):
    img = similar_images[i]
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.subplot(2,3,1+i)
    plt.imshow(img, cmap='gray')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## TESTING WITH EXTERNAL DATA"""

# Load the test image
test_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/truck.jpg')
#test_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/bird.jpg')

print('Query image:')
plt.imshow(test_image, cmap='gray')
plt.show()
# Convert the test image to grayscale and resize it to (32, 32)
test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
test_image_resized = cv2.resize(test_image_gray, (32, 32))

# Compute the visual word histogram for the test image
test_image_histogram = np.zeros((100,))
for i in range(0, 32, 8):
    for j in range(0, 32, 8):
        patch = test_image_resized[i:i+8, j:j+8]
        hist, _ = np.histogram(patch, bins=range(101))
        test_image_histogram[np.argmax(hist)] += 1

# Retrieve the top-5 similar images
similar_images, distances,labels= retrieve_similar_images(test_image_histogram, x_train_histograms, x_train,y_train)

# Display the query image and the top-5 similar images

print("Top 5 similar images")
for i in range(5):
    img = similar_images[i]
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.subplot(2,3,1+i)
    plt.imshow(img, cmap='gray')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

"""## PLOTTING OF P-R CURVE"""

from sklearn.metrics import precision_recall_curve
from sklearn.metrics import precision_recall_curve, average_precision_score

# Load the test image
test_image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/truck.jpg')

print('Query image:')
plt.imshow(test_image, cmap='gray')
plt.show()

# Convert the test image to grayscale and resize it to (32, 32)
test_image_gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)
test_image_resized = cv2.resize(test_image_gray, (32, 32))

# Compute the visual word histogram for the test image
test_image_histogram = np.zeros((100,))
for i in range(0, 32, 8):
    for j in range(0, 32, 8):
        patch = test_image_resized[i:i+8, j:j+8]
        hist, _ = np.histogram(patch, bins=range(101))
        test_image_histogram[np.argmax(hist)] += 1

# Retrieve the top-5 similar images and their labels
similar_images, distances, labels = retrieve_similar_images(test_image_histogram, x_train_histograms, x_train, y_train)

# Construct y_true
y_true = np.zeros((len(labels),))
for i, label in enumerate(labels):
    if label == y_test[0]:
        y_true[i] = 1

# Compute precision, recall, and PR curve
precisions, recalls, thresholds = precision_recall_curve(y_true, -distances)
average_precision = average_precision_score(y_true, -distances)
average_recall = np.array([1, 2, 3, 4, 5])
avg = np.mean(recalls)

print("Precision is :",average_precision)
print("Recall is :",avg)
plt.plot(recalls, precisions)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('PR Curve (AP={:.3f})'.format(average_precision))
plt.show()