# -*- coding: utf-8 -*-
"""M22RM002_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XzPaY58kLxj5TV_eXY5eIK71Bcatbo2r
"""

from google.colab import drive
drive.mount('/content/drive')

"""## METHOD-1"""

import glob
import math
import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn import preprocessing
from google.colab.patches import cv2_imshow

training_path="/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/face-lfw-train"
test_path="/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/virat_test.jpg"

def get_filepaths(directory):
   
    file_paths = []  # List which will store all of the full filepaths.

    # Walk the tree.
    for root, directories, files in os.walk(directory):
        for filename in files:
            filepath = os.path.join(filename)
            file_paths.append(filepath)
            print(file_paths)

    return file_paths

total_images = 0
height = 80
width = 70
images_paths = get_filepaths(training_path)
categories = []

for image_path in images_paths:
    category_parts = (image_path.split(".")[0]).split("_")
    if len(category_parts) < 2:
        # Invalid image filename format, skip this file
        continue
    category_str = category_parts[1]
    try:
        category = int(category_str)
    except ValueError:
        continue
    if category not in categories:
        categories.append(category)

categories = sorted(categories)
class_num = len(categories)

training_images = np.ndarray(shape=(len(images_paths), height*width), dtype=np.float64)
test_list=[]
for i in range(len(images_paths)):
    path= training_path+'/'+ images_paths[i]
    read_image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    resized_image = cv2.resize(read_image, (width, height))
    training_images[i,:] = np.array(resized_image, dtype='float64').flatten()
    test_list.append(resized_image)
    
print(training_images.shape)

print(len(test_list))

# All images are shown here
for i in range(len(images_paths)):
    img = training_images[i].reshape(height,width)
    plt.subplot(3,4,1+i)
    plt.imshow(img, cmap='gray')
plt.show()

##Get Mean Face
mean_face = np.zeros((1,height*width))

for i in training_images:
    mean_face = np.add(mean_face,i)

mean_face = np.divide(mean_face,float(len(images_paths))).flatten()

plt.imshow(mean_face.reshape(height, width), cmap='gray')
plt.show()

##Normailze Faces##
normalised_training = np.ndarray(shape=(len(images_paths), height*width))
for i in range(len(images_paths)):
    normalised_training[i] = np.subtract(training_images[i],mean_face)
print(len(normalised_training))

for i in range(len(images_paths)):
    img = normalised_training[i].reshape(height,width)
    plt.subplot(3,4,1+i)
    plt.imshow(img, cmap='gray')
    plt.tick_params(labelleft='off', labelbottom='off', bottom='off',top='off',right='off',left='off', which='both')
plt.show()

#covariance matrix
cov_matrix = ((normalised_training).dot(normalised_training.T))
cov_matrix = np.divide(cov_matrix ,float(len(normalised_training)))

eigenvalues, eigenvectors, = np.linalg.eig(cov_matrix)
print('Eigenvectors of Cov(X): \n%s' %eigenvectors)
print('\nEigenvalues of Cov(X): \n%s' %eigenvalues)

eig_pairs = [(eigenvalues[index], eigenvectors[:,index]) for index in range(len(eigenvalues))]
# Sort the eigen pairs in descending order:
eig_pairs.sort(reverse=True)
eigvalues_sort  = [eig_pairs[index][0] for index in range(len(eigenvalues))]
eigvectors_sort = [eig_pairs[index][1] for index in range(len(eigenvalues))]
eigenfaces = preprocessing.normalize(eigvectors_sort)
var_comp_sum = np.cumsum(eigvalues_sort)/sum(eigvalues_sort)
print(eigenfaces.shape)

reduced_data=[]
for i in (var_comp_sum):
    if i < 0.91:
        reduced_data.append(i)
reduced_data = np.array(eigenfaces[:77]).transpose()

proj_data = np.dot(training_images.transpose(),reduced_data)
proj_data = proj_data.transpose()
w = np.array([np.dot(proj_data,i) for i in normalised_training])
for i in range(10):
    img = proj_data[i].reshape(height,width)
    plt.subplot(2,5,1+i)
    plt.imshow(img, cmap='gray')
plt.show()

path_unknown ="/content/drive/MyDrive/Colab Notebooks/CV_ASSIGN_3/virat_test_2.jpg"
unknown_face = cv2.imread(path_unknown, cv2.IMREAD_GRAYSCALE)
unknown_face = cv2.resize(unknown_face, (width, height))
unknown_face_vector = np.array(unknown_face, dtype='float64').flatten()
normalised_uface_vector = np.subtract(unknown_face_vector,mean_face)
w_unknown = np.dot(proj_data, normalised_uface_vector)
euclidean_distance = np.linalg.norm(w - w_unknown, axis=1)
best_match = np.argmin(euclidean_distance)
# Visualize
fig, axes = plt.subplots(1,2,sharex=True,sharey=True,figsize=(8,6))
axes[0].imshow(unknown_face_vector.reshape(80,70), cmap="gray")
axes[0].set_title("Query")
axes[1].imshow(training_images[best_match].reshape(80,70), cmap="gray")
axes[1].set_title("Best match")
plt.show()

"""## METHOD-2"""

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from os import listdir
from os.path import isfile, join

# Getting the names of all images
file_names = [f for f in listdir(training_path) if isfile(join(training_path, f))]

import os

concat = []
file_names = os.listdir(training_path)

for name in file_names:
    file_path = os.path.join(training_path, name)
    x = Image.open(file_path).resize((64,64), Image.NEAREST)
    concat.append(np.asarray(x.convert('RGB'), dtype = "float32").reshape((4096,3)))
X = np.array(concat)

# Different Channels
X_1 = X[:,:,0]
X_2 = X[:,:,1]
X_3 = X[:,:,2]

"""## PCA"""

mean_1 = np.mean(X_1, axis = 0)
mean_2 = np.mean(X_2, axis = 0)
mean_3 = np.mean(X_3, axis = 0)

X_1 = X_1 - mean_1
X_2 = X_2 - mean_2
X_3 = X_3 - mean_3

# Cov Matrix and Eigen vectors / values for X_1
cov_matrix = np.cov(X_1)
eigen_values,eigen_vectors = np.linalg.eigh(cov_matrix) #np.linalg.eigh gives you SORTED!!! eigen values in ascending order 
eigen_vectors_1 = eigen_vectors
#First 10
component_vectors_1 = eigen_vectors[-10:]
component_values_1 = eigen_values[-10:]

explained_variance_1 = component_values_1 / np.sum(eigen_values)
print("Total Variance for channel 1:", np.sum(component_values_1 / np.sum(eigen_values)))

# Cov Matrix and Eigen vectors / values for X_2
cov_matrix = np.cov(X_2)
eigen_values,eigen_vectors = np.linalg.eigh(cov_matrix) #np.linalg.eigh gives you SORTED!!! eigen values in ascending order 
#First 10
eigen_vectors_2 = eigen_vectors 
component_vectors_2 = eigen_vectors[-10:]
component_values_2 = eigen_values[-10:]

explained_variance_2 = component_values_2 / np.sum(eigen_values)
print("Total Variance for channel 2:", np.sum(component_values_2 / np.sum(eigen_values)))

# Cov Matrix and Eigen vectors / values for X_3
cov_matrix = np.cov(X_3)
eigen_values,eigen_vectors = np.linalg.eigh(cov_matrix) #np.linalg.eigh gives you SORTED!!! eigen values in ascending order 
#First 10
eigen_vectors_3 = eigen_vectors
component_vectors_3 = eigen_vectors[-10:]
component_values_3 = eigen_values[-10:]

explained_variance_3 = component_values_3 / np.sum(eigen_values)
print("Total Variance  for channel 3:", np.sum(component_values_3 / np.sum(eigen_values)))

"""## SHOWING EIGEN FACES"""

components_1 = component_vectors_1.dot(X_1).reshape(10,64,64)
components_2 = component_vectors_2.dot(X_2).reshape(10,64,64)
components_3 = component_vectors_3.dot(X_3).reshape(10,64,64)

components_1 = (components_1 - np.min(components_1))/ (np.max(components_1) - np.min(components_1))
components_2 = (components_2 - np.min(components_2))/ (np.max(components_2) - np.min(components_2))
components_3 = (components_3 - np.min(components_3))/ (np.max(components_3) - np.min(components_3))

images = np.stack((components_1,components_2,components_3), axis = 3) 
f = plt.figure(figsize = (10,10))
for i in range(images.shape[0]):
    f.add_subplot(5,2 , i + 1)
    plt.imshow(images[i])

plt.show(block=True)

"""## Part 3 (Reconstructing an original facial image using the k principal components  k âˆˆ {1, 50, 250, 500, 1000})"""

first_image_index = 10
k = [1, 5, 10,100, 200]
fig = plt.figure(figsize=(6, 6))
columns = 2
rows = 3
i=1
for nb in k:
    comp1 = np.dot(eigen_vectors_1[-nb:],X_1)
    comp2 = np.dot(eigen_vectors_2[-nb:],X_2)
    comp3 = np.dot(eigen_vectors_3[-nb:],X_3)
    
    rec1 = (np.dot(eigen_vectors_1[-nb:].transpose(),comp1) + mean_1)#.reshape(eigen_vectors.shape[0],64,64)
    rec2 = (np.dot(eigen_vectors_2[-nb:].transpose(),comp2) + mean_2)#.reshape(eigen_vectors.shape[0],64,64)
    rec3 = (np.dot(eigen_vectors_3[-nb:].transpose(),comp3) + mean_3)#.reshape(eigen_vectors.shape[0],64,64)
    img = np.stack((rec1[first_image_index].reshape((64,64)),rec2[first_image_index].reshape((64,64)),rec3[first_image_index].reshape((64,64))), axis = 2)
    img = (img - np.min(img))/ (np.max(img) - np.min(img))
    fig.add_subplot(columns,rows,i)
    i += 1
    
    plt.imshow(img)

plt.show()

